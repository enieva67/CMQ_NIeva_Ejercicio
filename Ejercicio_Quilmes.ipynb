{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074b3f8c-af36-4e2e-a19a-1fe1ed37e062",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ng/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a5658c-845a-4851-8b58-9abdd7226a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clientes=pd.read_csv('Datos/clients.csv')\n",
    "\n",
    "segmento=pd.read_csv('Datos/channel_segmentation.csv')\n",
    "\n",
    "sales_2022_semestre_1=pd.read_csv( 'Datos/sales_2022_semestre_1.csv')\n",
    "sales_2022_semestre_2=pd.read_csv( 'Datos/sales_2022_semestre_2.csv')\n",
    "sales_2023_semestre_1=pd.read_csv( 'Datos/sales_2023_semestre_1.csv')\n",
    "\n",
    "clientes_con_promociones= pd.read_csv('Datos/coupons.csv')\n",
    "\n",
    "blacklist=pd.read_csv('Datos/blacklist.csv')\n",
    "\n",
    "datos=[sales_2022_semestre_1,sales_2022_semestre_2,sales_2023_semestre_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1878a21b-5f95-4b55-80f5-5fe250acf414",
   "metadata": {},
   "source": [
    "# Explicación del Código\n",
    "\n",
    "En este documento, se describe el proceso de lectura de varios archivos CSV que contienen datos relevantes para el análisis de clientes y ventas. Los archivos se cargan en diferentes DataFrames de pandas para su posterior manipulación y análisis.\n",
    "\n",
    "## Lectura de Archivos CSV\n",
    "\n",
    "El primer paso consiste en cargar los datos desde archivos CSV ubicados en la carpeta `Datos`. Utilizamos la función `pd.read_csv` de la biblioteca pandas para leer cada archivo y almacenar su contenido en un DataFrame.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Lectura de archivos CSV\n",
    "clientes = pd.read_csv('Datos/clients.csv')\n",
    "segmento = pd.read_csv('Datos/channel_segmentation.csv')\n",
    "sales_2022_semestre_1 = pd.read_csv('Datos/sales_2022_semestre_1.csv')\n",
    "sales_2022_semestre_2 = pd.read_csv('Datos/sales_2022_semestre_2.csv')\n",
    "sales_2023_semestre_1 = pd.read_csv('Datos/sales_2023_semestre_1.csv')\n",
    "clientes_con_promociones = pd.read_csv('Datos/coupons.csv')\n",
    "blacklist = pd.read_csv('Datos/blacklist.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed1ad60-c6f1-42e0-b35c-468d3b169924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1f2dc2a24942e3870cc96f0d0d8a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Marca:', options=('andes_origen', 'brahma', 'budweiser', 'corona', 'otras…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sales = pd.concat([sales_2022_semestre_1, sales_2022_semestre_2, sales_2023_semestre_1], ignore_index=True)\n",
    "ventas=pd.DataFrame(sales.groupby(['yearmonth','brand'])['sales'].sum()).sort_values(by='yearmonth').reset_index()\n",
    "\n",
    "# Función para actualizar el gráfico según la marca seleccionada\n",
    "def update_graph(marca):\n",
    "    plt.clf()  # Limpiar el gráfico anterior\n",
    "    \n",
    "    # Filtrar los datos para la marca seleccionada\n",
    "    data_filtered = ventas[ventas['brand'] == marca]\n",
    "    \n",
    "    # Configurar el estilo\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    barplot = sns.barplot(x='yearmonth', y='sales', data=data_filtered, palette='viridis', alpha=0.7)\n",
    "\n",
    "    # Añadir etiquetas y título\n",
    "    plt.title(f'Evolución de ventas de Cerveza - {marca}', fontsize=13)\n",
    "    plt.xlabel('Periodo', fontsize=11)\n",
    "    plt.ylabel('Ventas', fontsize=11)\n",
    "\n",
    "    # Girar las etiquetas del eje x\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=7)\n",
    "    plt.yticks(fontsize=9)\n",
    "\n",
    "    # Añadir etiquetas de datos en las barras\n",
    "    for p in barplot.patches:\n",
    "        barplot.annotate(format(p.get_height(), '.1f'), \n",
    "                         (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                         ha='center', va='center', \n",
    "                         xytext=(0, 7),  # Distancia del texto a la barra\n",
    "                         textcoords='offset points',\n",
    "                         fontsize=7)  # Tamaño de la fuente más pequeño\n",
    "\n",
    "    # Mejorar el diseño del gráfico\n",
    "    sns.despine(left=True, bottom=True)\n",
    "\n",
    "    # Mostrar el gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Obtener la lista única de marcas\n",
    "marcas = ventas['brand'].unique()\n",
    "\n",
    "# Crear el widget de selección de marca\n",
    "marca_widget = widgets.Dropdown(\n",
    "    options=marcas,\n",
    "    value=marcas[0],  # Valor por defecto\n",
    "    description='Marca:'\n",
    ")\n",
    "\n",
    "# Asociar la función de actualización al cambio en el widget\n",
    "output = widgets.interactive_output(update_graph, {'marca': marca_widget})\n",
    "\n",
    "# Mostrar el widget y la salida del gráfico\n",
    "display(widgets.HBox([marca_widget, output]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5762b-d525-44cb-8ea5-6b45b82c1f5f",
   "metadata": {},
   "source": [
    "### Descripción del Código\n",
    "\n",
    "El código proporcionado realiza las siguientes tareas:\n",
    "\n",
    "1. **Preparación de los Datos:**\n",
    "   \n",
    "   ```python\n",
    "   sales = pd.concat([sales_2022_semestre_1, sales_2022_semestre_2, sales_2023_semestre_1], ignore_index=True)\n",
    "   ventas = pd.DataFrame(sales.groupby(['yearmonth', 'brand'])['sales'].sum()).sort_values(by='yearmonth').reset_index()\n",
    "   ```\n",
    "   \n",
    "   - **`sales = pd.concat([...], ignore_index=True)`**: Combina varios DataFrames (`sales_2022_semestre_1`, `sales_2022_semestre_2`, `sales_2023_semestre_1`) en uno solo (`sales`), ignorando los índices originales para tener un índice continuo.\n",
    "   \n",
    "   - **`ventas = pd.DataFrame([...])`**: Agrupa los datos combinados por mes (`yearmonth`) y marca (`brand`), sumando las ventas (`sales`) para cada combinación. Luego, se ordenan los resultados por mes (`yearmonth`) y se resetea el índice para obtener un DataFrame limpio (`ventas`) listo para la visualización.\n",
    "\n",
    "2. **Función `update_graph`:**\n",
    "\n",
    "   ```python\n",
    "   def update_graph(marca):\n",
    "       plt.clf()  # Limpiar el gráfico anterior\n",
    "       \n",
    "       # Filtrar los datos para la marca seleccionada\n",
    "       data_filtered = ventas[ventas['brand'] == marca]\n",
    "       \n",
    "       # Configurar el estilo\n",
    "       sns.set(style=\"whitegrid\")\n",
    "   \n",
    "       # Crear el gráfico\n",
    "       plt.figure(figsize=(9, 6))\n",
    "       barplot = sns.barplot(x='yearmonth', y='sales', data=data_filtered, palette='viridis', alpha=0.7)\n",
    "   \n",
    "       # Añadir etiquetas y título\n",
    "       plt.title(f'Evolución de ventas de Cerveza - {marca}', fontsize=13)\n",
    "       plt.xlabel('Periodo', fontsize=11)\n",
    "       plt.ylabel('Ventas', fontsize=11)\n",
    "   \n",
    "       # Girar las etiquetas del eje x\n",
    "       plt.xticks(rotation=45, ha='right', fontsize=7)\n",
    "       plt.yticks(fontsize=9)\n",
    "   \n",
    "       # Añadir etiquetas de datos en las barras\n",
    "       for p in barplot.patches:\n",
    "           barplot.annotate(format(p.get_height(), '.1f'), \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                            ha='center', va='center', \n",
    "                            xytext=(0, 7),  # Distancia del texto a la barra\n",
    "                            textcoords='offset points',\n",
    "                            fontsize=7)  # Tamaño de la fuente más pequeño\n",
    "   \n",
    "       # Mejorar el diseño del gráfico\n",
    "       sns.despine(left=True, bottom=True)\n",
    "   \n",
    "       # Mostrar el gráfico\n",
    "       plt.tight_layout()\n",
    "       plt.show()\n",
    "   ```\n",
    "   \n",
    "   - **`update_graph(marca)`**: Esta función toma como argumento `marca`, que representa la marca de cerveza seleccionada por el usuario.\n",
    "   \n",
    "   - **`plt.clf()`**: Limpia cualquier gráfico previo para asegurar que se dibuje uno nuevo sin superposiciones.\n",
    "   \n",
    "   - **Filtrado de Datos**: Filtra el DataFrame `ventas` para obtener solo las filas donde la columna `brand` coincide con la `marca` seleccionada.\n",
    "   \n",
    "   - **Configuración del Gráfico**:\n",
    "     - `sns.set(style=\"whitegrid\")`: Configura el estilo de Seaborn para el gráfico.\n",
    "     - `plt.figure(figsize=(9, 6))`: Define el tamaño del gráfico.\n",
    "     - `sns.barplot(...)`: Crea un gráfico de barras usando Seaborn, donde `yearmonth` se representa en el eje x, `sales` en el eje y, y `data_filtered` contiene los datos filtrados para la marca seleccionada.\n",
    "   \n",
    "   - **Añadir Etiquetas y Título**: Configura el título del gráfico y etiquetas para los ejes x e y.\n",
    "   \n",
    "   - **Etiquetas de Datos**: Utiliza `annotate` para agregar etiquetas de datos en las barras del gráfico.\n",
    "   \n",
    "   - **Mejoras Estéticas**: `sns.despine()` elimina los bordes izquierdo y inferior del gráfico para mejorar la estética.\n",
    "   \n",
    "   - **Mostrar el Gráfico**: `plt.tight_layout()` asegura que todos los elementos del gráfico sean visibles correctamente, y `plt.show()` muestra el gráfico en el notebook.\n",
    "\n",
    "3. **Widget Interactivo:**\n",
    "   \n",
    "   ### Obtener la lista única de marcas\n",
    "   marcas = ventas['brand'].unique()\n",
    "   \n",
    "   ### Crear el widget de selección de marca\n",
    "   marca_widget = widgets.Dropdown(\n",
    "       options=marcas,\n",
    "       value=marcas[0],  # Valor por defecto\n",
    "       description='Marca:'\n",
    "   )\n",
    "   \n",
    "   ### Asociar la función de actualización al cambio en el widget\n",
    "   output = widgets.interactive_output(update_graph, {'marca': marca_widget})\n",
    "   \n",
    "   ### Mostrar el widget y la salida del gráfico\n",
    "   display(widgets.HBox([marca_widget, output]))\n",
    "   \n",
    "   \n",
    "   - **Creación del Widget**: `widgets.Dropdown` crea un menú desplegable (`Dropdown`) con opciones basadas en las marcas únicas presentes en `ventas`.\n",
    "   \n",
    "   - **Asociación de la Función `update_graph`**: `widgets.interactive_output` conecta dinámicamente el widget de selección de marca (`marca_widget`) con la función `update_graph`, de modo que cada vez que se selecciona una marca, se llama automáticamente a `update_graph` con el valor seleccionado como argumento.\n",
    "   \n",
    "   - **Mostrar el Widget y la Salida**: `display(widgets.HBox([...]))` muestra el widget de selección de marca y la salida interactiva del gráfico en una misma fila (`HBox`), permitiendo una interacción fácil y clara en el notebook.\n",
    "\n",
    "Este código crea un entorno interactivo donde los usuarios pueden seleccionar una marca de cerveza y ver la evolución de las ventas representada en un gráfico de barras, adaptado dinámicamente según la selección realizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f43eead2-d1c9-44f2-9a61-533ae256fc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in datos:\n",
    "    df=i\n",
    "    df['yearmonth'] = df['yearmonth'].apply(str)\n",
    "    df['year'] = df['yearmonth'].str[:4]\n",
    "    df['mes'] = df['yearmonth'].str[4:]\n",
    "    i=df\n",
    "\n",
    "df=clientes_con_promociones \n",
    "df['yearmonth'] = df['yearmonth'].apply(str)\n",
    "df['year'] = df['yearmonth'].str[:4]\n",
    "df['mes'] = df['yearmonth'].str[4:]\n",
    "clientes_con_promociones=df    \n",
    "\n",
    "sales_2022_s1merged = pd.merge(sales_2022_semestre_1,clientes_con_promociones, on=['cliente_id','business', 'brand','yearmonth','year','mes'], how='left')\n",
    "sales_2022_s2merged = pd.merge(sales_2022_semestre_2,clientes_con_promociones, on=['cliente_id','business', 'brand','yearmonth','year','mes'], how='left')\n",
    "sales_2023_s1merged = pd.merge(sales_2023_semestre_1,clientes_con_promociones, on=['cliente_id','business', 'brand','yearmonth','year','mes'], how='left')\n",
    "\n",
    "sales_2022_s1merged['sales_with_coupons'].fillna(0, inplace=True) \n",
    "sales_2022_s2merged['sales_with_coupons'].fillna(0, inplace=True)\n",
    "sales_2023_s1merged['sales_with_coupons'].fillna(0, inplace=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102caa16-ba77-459f-9dcb-48e7ef124760",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explicación del Código\n",
    "\n",
    "En este documento, se describe el proceso de manipulación y fusión de datos de ventas con datos de promociones, y la limpieza de los datos resultantes. Este proceso incluye la transformación de columnas, la fusión de DataFrames y el manejo de valores nulos.\n",
    "\n",
    "## Transformación de Columnas en los DataFrames de Ventas\n",
    "\n",
    "Primero, recorremos la lista `datos`, que contiene los DataFrames de ventas de diferentes semestres, y transformamos la columna `yearmonth` en dos nuevas columnas: `year` y `mes`.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Transformar la columna 'yearmonth' en 'year' y 'mes' para los DataFrames de ventas\n",
    "for i in datos:\n",
    "    df = i\n",
    "    df['yearmonth'] = df['yearmonth'].apply(str)\n",
    "    df['year'] = df['yearmonth'].str[:4]\n",
    "    df['mes'] = df['yearmonth'].str[4:]\n",
    "    i = df\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **`yearmonth` a cadena**: Convertimos la columna `yearmonth` a una cadena de texto para facilitar la extracción de `year` y `mes`.\n",
    "- **Extracción de `year` y `mes`**: Utilizamos el método `str` para extraer los primeros 4 caracteres como `year` y los siguientes caracteres como `mes`.\n",
    "\n",
    "## Transformación de Columnas en el DataFrame de Promociones\n",
    "\n",
    "Realizamos una transformación similar en el DataFrame `clientes_con_promociones`.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Transformar la columna 'yearmonth' en 'year' y 'mes' para el DataFrame de promociones\n",
    "df = clientes_con_promociones\n",
    "df['yearmonth'] = df['yearmonth'].apply(str)\n",
    "df['year'] = df['yearmonth'].str[:4]\n",
    "df['mes'] = df['yearmonth'].str[4:]\n",
    "clientes_con_promociones = df\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Transformaciones idénticas**: Aplicamos el mismo proceso de transformación que en los DataFrames de ventas para asegurar la consistencia en los formatos de las columnas.\n",
    "\n",
    "## Fusión de DataFrames\n",
    "\n",
    "Fusionamos los DataFrames de ventas con el DataFrame `clientes_con_promociones` para agregar información de promociones a los datos de ventas.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Fusión de DataFrames de ventas con clientes con promociones\n",
    "sales_2022_s1merged = pd.merge(sales_2022_semestre_1, clientes_con_promociones, on=['cliente_id', 'business', 'brand', 'yearmonth', 'year', 'mes'], how='left')\n",
    "sales_2022_s2merged = pd.merge(sales_2022_semestre_2, clientes_con_promociones, on=['cliente_id', 'business', 'brand', 'yearmonth', 'year', 'mes'], how='left')\n",
    "sales_2023_s1merged = pd.merge(sales_2023_semestre_1, clientes_con_promociones, on=['cliente_id', 'business', 'brand', 'yearmonth', 'year', 'mes'], how='left')\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Fusión (`merge`)**: Utilizamos `pd.merge` para combinar los DataFrames de ventas con `clientes_con_promociones` basado en las columnas `cliente_id`, `business`, `brand`, `yearmonth`, `year`, y `mes`.\n",
    "- **Método `left join`**: Usamos `how='left'` para mantener todos los registros de las ventas, incluso si no tienen correspondencia en `clientes_con_promociones`.\n",
    "\n",
    "## Manejo de Valores Nulos\n",
    "\n",
    "Llenamos los valores nulos en la columna `sales_with_coupons` con 0 en los DataFrames resultantes de las fusiones.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Llenar valores nulos en 'sales_with_coupons' con 0\n",
    "sales_2022_s1merged['sales_with_coupons'].fillna(0, inplace=True)\n",
    "sales_2022_s2merged['sales_with_coupons'].fillna(0, inplace=True)\n",
    "sales_2023_s1merged['sales_with_coupons'].fillna(0, inplace=True)\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Llenar valores nulos**: Utilizamos `fillna(0, inplace=True)` para reemplazar los valores nulos en la columna `sales_with_coupons` con 0. Esto asegura que las ventas sin cupones se registren como 0 en lugar de nulos.\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "Este código realiza varias transformaciones y fusiones esenciales para preparar los datos de ventas y promociones para análisis posteriores. Al transformar y fusionar los DataFrames, y manejar los valores nulos, garantizamos que los datos estén en un formato consistente y listo para el análisis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f47850e2-af04-4ca5-a2bc-3e2d97ea599e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_2022_s1merged['promocion']=np.where(sales_2022_s1merged['sales_with_coupons']>5,1,0)\n",
    "sales_2023_s1merged['promocion']=np.where(sales_2023_s1merged['sales_with_coupons']>5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d67b8a4-cd9c-45e8-a68f-75eb9419b03e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_merged_s1= pd.merge(sales_2022_s1merged, sales_2023_s1merged, on=['cliente_id','business', 'brand','mes'], how='inner', suffixes=('', '_next'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d44165-fb20-45ee-82d7-b59c31f34179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clientes_merged_df = pd.merge(clientes, segmento, on='channel_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc16411-9572-4c06-bfd0-ad4c2caab45d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=clientes_merged_df\n",
    "clientes_merged_filtrado= df[~df['cliente_id'].isin(blacklist['cliente_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78037cc2-9eb0-430c-bb93-b457eb4fba7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3859/3750928818.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_fit['proporcion']=(target_fit['sales_next']-target_fit['sales'])/target_fit['sales']\n",
      "/tmp/ipykernel_3859/3750928818.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_fit['proporcion']=(control_fit['sales_next']-control_fit['sales'])/control_fit['sales']\n"
     ]
    }
   ],
   "source": [
    "clientes_merged_df = pd.merge(clientes_merged_filtrado, sales_merged_s1, on='cliente_id', how='inner')\n",
    "clientes_merged_df['target_de_estudio']=np.where((clientes_merged_df['promocion']==0) & (clientes_merged_df['promocion_next']==1),1,0)\n",
    "clientes_merged_df['control']=np.where((clientes_merged_df['promocion']==0) & (clientes_merged_df['promocion_next']==0),1,0)\n",
    "\n",
    "target = clientes_merged_df[clientes_merged_df['target_de_estudio']==1]\n",
    "\n",
    "control=clientes_merged_df[clientes_merged_df['control']==1]\n",
    "\n",
    "rubros = ['AUTOSERVICIOS', 'KIOSCOS', 'TRADICIONAL']\n",
    "\n",
    "target_fit=target[(target['sales']>0.1) & (target['channel_segmentation'].isin(rubros))]\n",
    "control_fit=control[(control['sales']>0.1) & (control['channel_segmentation'].isin(rubros))]\n",
    "\n",
    "target_fit['proporcion']=(target_fit['sales_next']-target_fit['sales'])/target_fit['sales']\n",
    "control_fit['proporcion']=(control_fit['sales_next']-control_fit['sales'])/control_fit['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2ac3c-e666-4c9f-b9fc-b399a143947b",
   "metadata": {},
   "source": [
    "\n",
    "# Explicación del Código\n",
    "\n",
    "En este documento, se describe un proceso complejo de análisis de datos, que incluye la creación de variables, la fusión de DataFrames y la identificación de grupos de estudio y control. Este proceso es crucial para analizar el impacto de las promociones en las ventas de los clientes.\n",
    "\n",
    "## Creación de la Variable de Promoción\n",
    "\n",
    "Primero, se crea una nueva columna `promocion` en los DataFrames de ventas de 2022 y 2023 que indica si las ventas con cupones superan un umbral específico (en este caso, 5).\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Crear columna 'promocion' para indicar si 'sales_with_coupons' > 5\n",
    "sales_2022_s1merged['promocion'] = np.where(sales_2022_s1merged['sales_with_coupons'] > 5, 1, 0)\n",
    "sales_2023_s1merged['promocion'] = np.where(sales_2023_s1merged['sales_with_coupons'] > 5, 1, 0)\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Condición `np.where`**: Si `sales_with_coupons` es mayor a 5, se asigna 1 (promoción); de lo contrario, se asigna 0.\n",
    "\n",
    "## Fusión de DataFrames de Ventas\n",
    "\n",
    "Fusionamos los DataFrames de ventas de 2022 y 2023, manteniendo sólo los registros que coinciden en ambas tablas (`inner join`).\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Fusionar DataFrames de ventas de 2022 y 2023\n",
    "sales_merged_s1 = pd.merge(sales_2022_s1merged, sales_2023_s1merged, on=['cliente_id', 'business', 'brand', 'mes'], how='inner', suffixes=('', '_next'))\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Fusión `inner join`**: Mantiene sólo los registros que están presentes en ambos DataFrames.\n",
    "- **Sufijos**: Se añaden sufijos para diferenciar las columnas del DataFrame de 2023 (`_next`).\n",
    "\n",
    "## Fusión de Clientes con Segmentos de Canal\n",
    "\n",
    "Fusionamos los DataFrames de clientes y segmentos de canal.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Fusionar DataFrames de clientes y segmentos de canal\n",
    "clientes_merged_df = pd.merge(clientes, segmento, on='channel_id', how='inner')\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Fusión `inner join`**: Mantiene sólo los registros que están presentes en ambos DataFrames.\n",
    "\n",
    "## Filtrado de Clientes en la Lista Negra\n",
    "\n",
    "Filtramos los clientes que están en la lista negra (`blacklist`).\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Filtrar clientes que no están en la lista negra\n",
    "df = clientes_merged_df\n",
    "clientes_merged_filtrado = df[~df['cliente_id'].isin(blacklist['cliente_id'])]\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Filtrado**: Excluimos los `cliente_id` que están en la lista negra usando `isin` y `~` para la negación.\n",
    "\n",
    "## Fusión de Clientes con Ventas\n",
    "\n",
    "Fusionamos los DataFrames de clientes filtrados con las ventas fusionadas de 2022 y 2023.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Fusionar clientes filtrados con ventas fusionadas\n",
    "clientes_merged_df = pd.merge(clientes_merged_filtrado, sales_merged_s1, on='cliente_id', how='inner')\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Fusión `inner join`**: Mantiene sólo los registros que están presentes en ambos DataFrames.\n",
    "\n",
    "## Creación de Variables de Estudio y Control\n",
    "\n",
    "Creamos nuevas columnas `target_de_estudio` y `control` para identificar los grupos de estudio y control.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Crear columna 'target_de_estudio'\n",
    "clientes_merged_df['target_de_estudio'] = np.where((clientes_merged_df['promocion'] == 0) & (clientes_merged_df['promocion_next'] == 1), 1, 0)\n",
    "\n",
    "# Crear columna 'control'\n",
    "clientes_merged_df['control'] = np.where((clientes_merged_df['promocion'] == 0) & (clientes_merged_df['promocion_next'] == 0), 1, 0)\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Condición `np.where`**: `target_de_estudio` se asigna 1 si `promocion` es 0 y `promocion_next` es 1; `control` se asigna 1 si `promocion` y `promocion_next` son 0.\n",
    "\n",
    "## Identificación de Grupos de Estudio y Control\n",
    "\n",
    "Filtramos los DataFrames para obtener los grupos de estudio y control.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Filtrar grupos de estudio y control\n",
    "target = clientes_merged_df[clientes_merged_df['target_de_estudio'] == 1]\n",
    "control = clientes_merged_df[clientes_merged_df['control'] == 1]\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Filtrado**: Seleccionamos los registros donde `target_de_estudio` es 1 para el grupo de estudio y `control` es 1 para el grupo de control.\n",
    "\n",
    "## Filtrado Adicional por Segmentos de Canal y Ventas\n",
    "\n",
    "Filtramos adicionalmente los grupos de estudio y control por segmentos de canal específicos y ventas mayores a 0.1.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Definir rubros específicos\n",
    "rubros = ['AUTOSERVICIOS', 'KIOSCOS', 'TRADICIONAL']\n",
    "\n",
    "# Filtrar grupos de estudio y control por ventas y segmentos de canal\n",
    "target_fit = target[(target['sales'] > 0.1) & (target['channel_segmentation'].isin(rubros))]\n",
    "control_fit = control[(control['sales'] > 0.1) & (control['channel_segmentation'].isin(rubros))]\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Filtrado**: Seleccionamos los registros con `sales` mayores a 0.1 y `channel_segmentation` en los rubros definidos.\n",
    "\n",
    "## Cálculo de la Proporción de Cambio en Ventas\n",
    "\n",
    "Calculamos la proporción de cambio en ventas entre 2022 y 2023 para los grupos de estudio y control.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Calcular proporción de cambio en ventas\n",
    "target_fit['proporcion'] = (target_fit['sales_next'] - target_fit['sales']) / target_fit['sales']\n",
    "control_fit['proporcion'] = (control_fit['sales_next'] - control_fit['sales']) / control_fit['sales']\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Cálculo de Proporción**: La proporción se calcula como el cambio en ventas entre 2023 y 2022 dividido por las ventas de 2022.\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "Este código realiza un análisis detallado de los datos de ventas y promociones, identificando y comparando grupos de estudio y control. Las transformaciones y fusiones de DataFrames aseguran que los datos estén en un formato adecuado para el análisis, permitiendo la evaluación del impacto de las promociones en las ventas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b14cff18-4d63-4a09-b818-f4c967fc281a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcular Q1 (primer cuartil) y Q3 (tercer cuartil)\n",
    "Q1 = target_fit['proporcion'].quantile(0.25)\n",
    "Q3 = target_fit['proporcion'].quantile(0.75)\n",
    "\n",
    "# Calcular el rango intercuartílico (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definir los límites para identificar outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtrar el DataFrame para eliminar los outliers\n",
    "target_fit_sin_outliers = target_fit[(target_fit['proporcion'] >= lower_bound) & (target_fit['proporcion'] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a20514-e0eb-44d2-909e-ae25a2fb3376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcular Q1 (primer cuartil) y Q3 (tercer cuartil)\n",
    "Q1 = control_fit['proporcion'].quantile(0.25)\n",
    "Q3 = control_fit['proporcion'].quantile(0.75)\n",
    "\n",
    "# Calcular el rango intercuartílico (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definir los límites para identificar outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtrar el DataFrame para eliminar los outliers\n",
    "control_fit_sin_outliers = control_fit[(control_fit['proporcion'] >= lower_bound) & (control_fit['proporcion'] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7415dc-7f1f-44b0-b9f0-b36ad2aa35a7",
   "metadata": {},
   "source": [
    "\n",
    "# Explicación del Código\n",
    "\n",
    "En este documento, se describe el proceso de identificación y eliminación de outliers en los grupos de estudio y control, utilizando el rango intercuartílico (IQR). Este proceso es esencial para asegurar que el análisis no esté influenciado por valores atípicos extremos.\n",
    "\n",
    "## Identificación y Eliminación de Outliers\n",
    "\n",
    "### Para el Grupo de Estudio (`target_fit`)\n",
    "\n",
    "Primero, calculamos el primer cuartil (Q1) y el tercer cuartil (Q3) de la variable `proporcion`, que representa el cambio proporcional en ventas. A partir de estos valores, calculamos el rango intercuartílico (IQR) y definimos los límites para identificar outliers.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Calcular Q1 (primer cuartil) y Q3 (tercer cuartil) para el grupo de estudio\n",
    "Q1 = target_fit['proporcion'].quantile(0.25)\n",
    "Q3 = target_fit['proporcion'].quantile(0.75)\n",
    "\n",
    "# Calcular el rango intercuartílico (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definir los límites para identificar outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtrar el DataFrame para eliminar los outliers\n",
    "target_fit_sin_outliers = target_fit[(target_fit['proporcion'] >= lower_bound) & (target_fit['proporcion'] <= upper_bound)]\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Cálculo de Q1 y Q3**: Utilizamos el método `quantile` para calcular el primer y tercer cuartil de la columna `proporcion`.\n",
    "- **Cálculo del IQR**: El rango intercuartílico se calcula como la diferencia entre Q3 y Q1.\n",
    "- **Definición de Límites**: Los límites inferior y superior para identificar outliers se definen como \\( Q1 - 1.5 \\times IQR \\) y \\( Q3 + 1.5 \\times IQR \\), respectivamente.\n",
    "- **Filtrado de Outliers**: Filtramos el DataFrame para mantener solo los valores de `proporcion` que están dentro de los límites definidos.\n",
    "\n",
    "### Para el Grupo de Control (`control_fit`)\n",
    "\n",
    "Repetimos el mismo proceso para el grupo de control.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Calcular Q1 (primer cuartil) y Q3 (tercer cuartil) para el grupo de control\n",
    "Q1 = control_fit['proporcion'].quantile(0.25)\n",
    "Q3 = control_fit['proporcion'].quantile(0.75)\n",
    "\n",
    "# Calcular el rango intercuartílico (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definir los límites para identificar outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtrar el DataFrame para eliminar los outliers\n",
    "control_fit_sin_outliers = control_fit[(control_fit['proporcion'] >= lower_bound) & (control_fit['proporcion'] <= upper_bound)]\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Proceso Identico**: Se siguen los mismos pasos de cálculo y filtrado que en el grupo de estudio, adaptados al DataFrame `control_fit`.\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "Este código calcula los cuartiles y el rango intercuartílico para la variable `proporcion` en los grupos de estudio y control, y utiliza estos valores para definir y eliminar outliers. Este paso es crucial para asegurar que los análisis posteriores no se vean sesgados por valores atípicos extremos, proporcionando así resultados más precisos y fiables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab982728-0a29-44e7-bc95-3ee7b3817a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Agrupar por las columnas especificadas\n",
    "grouped = target_fit_sin_outliers.groupby(['channel_segmentation', 'brand', 'mes'])\n",
    "\n",
    "# Crear un diccionario para almacenar los DataFrames separados\n",
    "dataframes_target = {}\n",
    "\n",
    "# Iterar sobre los grupos y almacenar cada grupo en un DataFrame separado\n",
    "for name, group in grouped:\n",
    "    dataframes_target[name] = group.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "436e6813-3aeb-4767-85d4-e0ccbd8d1ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Agrupar por las columnas especificadas\n",
    "grouped = control_fit_sin_outliers.groupby(['channel_segmentation', 'brand', 'mes'])\n",
    "\n",
    "# Crear un diccionario para almacenar los DataFrames separados\n",
    "dataframes_control = {}\n",
    "\n",
    "# Iterar sobre los grupos y almacenar cada grupo en un DataFrame separado\n",
    "for name, group in grouped:\n",
    "    dataframes_control[name] = group.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30d1e10f-25ef-4833-9f3a-95c1317807ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear un diccionario para almacenar los deciles\n",
    "deciles_dict = {}\n",
    "\n",
    "# Calcular los deciles para cada DataFrame en el primer diccionario\n",
    "for key, df in dataframes_target.items():\n",
    "    deciles_dict[key] = df['sales'].quantile([0.1 * i for i in range(1, 10)]).values\n",
    "\n",
    "    # Crear un diccionario para almacenar las muestras del segundo diccionario\n",
    "sampled_dict = {}\n",
    "\n",
    "# Tomar una muestra de 10 casos para cada decil del segundo diccionario\n",
    "for key, df in dataframes_control.items():\n",
    "    if key in deciles_dict:\n",
    "        datos=dataframes_target[key]\n",
    "        deciles = deciles_dict[key]\n",
    "        samples = []\n",
    "        for i in range(len(deciles)):\n",
    "            if i == 0:\n",
    "                mask = (df['sales'] <= deciles[i]) & (df['region'].isin(datos['region'].unique()))\n",
    "            else:\n",
    "                mask = (df['sales'] > deciles[i-1]) & (df['sales'] <= deciles[i]) & (df['region'].isin(datos['region'].unique()))\n",
    "            \n",
    "            decil_sample = df[mask].sample(n=10, replace=True, random_state=1) if not df[mask].empty else pd.DataFrame()\n",
    "            samples.append(decil_sample)\n",
    "        \n",
    "        # Concatenar todas las muestras para este key\n",
    "        sampled_df = pd.concat(samples).reset_index(drop=True)\n",
    "        sampled_dict[key] = sampled_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bdf099-85ca-4577-a9bc-606e5340d0cf",
   "metadata": {},
   "source": [
    "\n",
    "# Explicación del Código\n",
    "\n",
    "En este documento, se describe el proceso de agrupación de DataFrames, cálculo de deciles y muestreo de datos en Python. Este proceso es esencial para preparar los datos para análisis posteriores.\n",
    "\n",
    "## Agrupación de DataFrames\n",
    "\n",
    "### Agrupación del Grupo de Estudio (`target_fit_sin_outliers`)\n",
    "\n",
    "Primero, agrupamos los datos del grupo de estudio por las columnas `channel_segmentation`, `brand` y `mes`.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Agrupar por las columnas especificadas\n",
    "grouped = target_fit_sin_outliers.groupby(['channel_segmentation', 'brand', 'mes'])\n",
    "\n",
    "# Crear un diccionario para almacenar los DataFrames separados\n",
    "dataframes_target = {}\n",
    "\n",
    "# Iterar sobre los grupos y almacenar cada grupo en un DataFrame separado\n",
    "for name, group in grouped:\n",
    "    dataframes_target[name] = group.reset_index(drop=True)\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Agrupación**: Utilizamos el método `groupby` de pandas para agrupar los datos por las columnas especificadas.\n",
    "- **Almacenamiento**: Creamos un diccionario `dataframes_target` donde cada grupo se almacena como un DataFrame separado, con las llaves del diccionario siendo las combinaciones de valores de las columnas agrupadas.\n",
    "\n",
    "### Agrupación del Grupo de Control (`control_fit_sin_outliers`)\n",
    "\n",
    "Repetimos el mismo proceso para el grupo de control.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Agrupar por las columnas especificadas\n",
    "grouped = control_fit_sin_outliers.groupby(['channel_segmentation', 'brand', 'mes'])\n",
    "\n",
    "# Crear un diccionario para almacenar los DataFrames separados\n",
    "dataframes_control = {}\n",
    "\n",
    "# Iterar sobre los grupos y almacenar cada grupo en un DataFrame separado\n",
    "for name, group in grouped:\n",
    "    dataframes_control[name] = group.reset_index(drop=True)\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Proceso Identico**: Se siguen los mismos pasos de agrupación y almacenamiento que en el grupo de estudio, adaptados al DataFrame `control_fit_sin_outliers`.\n",
    "\n",
    "## Cálculo de Deciles\n",
    "\n",
    "Calculamos los deciles de la columna `sales` para cada DataFrame en el diccionario del grupo de estudio.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Crear un diccionario para almacenar los deciles\n",
    "deciles_dict = {}\n",
    "\n",
    "# Calcular los deciles para cada DataFrame en el primer diccionario\n",
    "for key, df in dataframes_target.items():\n",
    "    deciles_dict[key] = df['sales'].quantile([0.1 * i for i in range(1, 10)]).values\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Diccionario de Deciles**: Creamos `deciles_dict` para almacenar los deciles calculados.\n",
    "- **Cálculo de Deciles**: Utilizamos el método `quantile` para calcular los deciles de la columna `sales` para cada DataFrame en `dataframes_target`.\n",
    "\n",
    "## Muestreo Basado en Deciles\n",
    "\n",
    "Tomamos muestras de 10 casos para cada decil del diccionario del grupo de control basado en los deciles calculados del grupo de estudio.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Crear un diccionario para almacenar las muestras del segundo diccionario\n",
    "sampled_dict = {}\n",
    "\n",
    "# Tomar una muestra de 10 casos para cada decil del segundo diccionario\n",
    "for key, df in dataframes_control.items():\n",
    "    if key in deciles_dict:\n",
    "        datos = dataframes_target[key]\n",
    "        deciles = deciles_dict[key]\n",
    "        samples = []\n",
    "        for i in range(len(deciles)):\n",
    "            if i == 0:\n",
    "                mask = (df['sales'] <= deciles[i]) & (df['region'].isin(datos['region'].unique()))\n",
    "            else:\n",
    "                mask = (df['sales'] > deciles[i-1]) & (df['sales'] <= deciles[i]) & (df['region'].isin(datos['region'].unique()))\n",
    "            \n",
    "            decil_sample = df[mask].sample(n=10, replace=True, random_state=1) if not df[mask].empty else pd.DataFrame()\n",
    "            samples.append(decil_sample)\n",
    "        \n",
    "        # Concatenar todas las muestras para este key\n",
    "        sampled_df = pd.concat(samples).reset_index(drop=True)\n",
    "        sampled_dict[key] = sampled_df\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Diccionario de Muestras**: Creamos `sampled_dict` para almacenar las muestras seleccionadas.\n",
    "- **Condición de Muestreo**: Para cada key en `dataframes_control` que también está en `deciles_dict`, filtramos las filas de acuerdo a los deciles calculados y tomamos muestras de 10 casos para cada decil.\n",
    "- **Concatenación de Muestras**: Concatenamos las muestras de cada decil y las almacenamos en `sampled_dict`.\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "Este código realiza la agrupación de DataFrames por columnas específicas, calcula los deciles de ventas y toma muestras de datos basadas en estos deciles. Este proceso prepara los datos para análisis posteriores, asegurando que cada segmento de datos se trate de manera adecuada y que las muestras sean representativas.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c189660b-88da-42fa-88ce-b70b1ae26427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "promedios_por_region_dict = {}\n",
    "\n",
    "# Calcular los promedios de 'proporcion' por región para cada DataFrame en el segundo diccionario\n",
    "for key, df in sampled_dict.items():\n",
    "    promedios_por_region = df.groupby('region')['proporcion'].mean().to_dict()\n",
    "    promedios_por_region_dict[key] = promedios_por_region\n",
    "\n",
    "# Mostrar los promedios por región\n",
    "#for key, promedios in promedios_por_region_dict.items():\n",
    "   # print(f'\\nPromedios de proporcion por región para {key}: {promedios}')\n",
    "\n",
    "# Añadir una nueva columna en el primer diccionario con los promedios de proporcion por región\n",
    "for key, df in dataframes_target.items():\n",
    "    if key in promedios_por_region_dict:\n",
    "        df['promedio_proporcion_region'] = df['region'].map(promedios_por_region_dict[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a433f2df-f7df-4a2e-b3cd-a2a293d95b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, df in dataframes_target.items():\n",
    "    df['lifts'] = df['proporcion']-df['promedio_proporcion_region']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68577fd-19ed-4618-8b7c-e1f91f25c0bf",
   "metadata": {},
   "source": [
    "\n",
    "# Explicación del Código\n",
    "\n",
    "En este documento, se describe el proceso de cálculo de los promedios de la variable `proporcion` por región, y la adición de una nueva columna que representa el promedio por región en los DataFrames del primer diccionario. Además, se calcula y añade una nueva columna que representa el lift, que es una medida del incremento porcentual en ventas generado por las campañas de marketing.\n",
    "\n",
    "## Calcular Promedios de `proporcion` por Región\n",
    "\n",
    "### Paso 1: Calcular los Promedios de `proporcion` por Región para cada DataFrame en el Segundo Diccionario (`sampled_dict`)\n",
    "\n",
    "Primero, calculamos los promedios de `proporcion` por región para cada DataFrame en el segundo diccionario y almacenamos estos promedios en un nuevo diccionario.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "promedios_por_region_dict = {}\n",
    "\n",
    "# Calcular los promedios de 'proporcion' por región para cada DataFrame en el segundo diccionario\n",
    "for key, df in sampled_dict.items():\n",
    "    promedios_por_region = df.groupby('region')['proporcion'].mean().to_dict()\n",
    "    promedios_por_region_dict[key] = promedios_por_region\n",
    "\n",
    "# Mostrar los promedios por región (opcional)\n",
    "# for key, promedios in promedios_por_region_dict.items():\n",
    "#     print(f'\\nPromedios de proporcion por región para {key}: {promedios}')\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Diccionario de Promedios**: Creamos `promedios_por_region_dict` para almacenar los promedios calculados.\n",
    "- **Cálculo de Promedios**: Utilizamos el método `groupby` y `mean` de pandas para calcular los promedios de `proporcion` por región para cada DataFrame en `sampled_dict`.\n",
    "- **Almacenamiento de Resultados**: Los promedios calculados se almacenan en `promedios_por_region_dict` con las keys correspondientes.\n",
    "\n",
    "## Añadir Promedios de `proporcion` por Región en el Primer Diccionario (`dataframes_target`)\n",
    "\n",
    "### Paso 2: Añadir una Nueva Columna en el Primer Diccionario con los Promedios de `proporcion` por Región\n",
    "\n",
    "Para cada DataFrame en el primer diccionario, añadimos una nueva columna `promedio_proporcion_region` que contiene el promedio de `proporcion` por región.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# Añadir una nueva columna en el primer diccionario con los promedios de proporcion por región\n",
    "for key, df in dataframes_target.items():\n",
    "    if key in promedios_por_region_dict:\n",
    "        df['promedio_proporcion_region'] = df['region'].map(promedios_por_region_dict[key])\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Añadir Columna de Promedio**: Utilizamos el método `map` para añadir una nueva columna `promedio_proporcion_region` que contiene los promedios de `proporcion` por región, obtenidos del diccionario `promedios_por_region_dict`.\n",
    "\n",
    "## Calcular y Añadir la Columna `lifts`\n",
    "\n",
    "### Paso 3: Calcular y Añadir la Columna `lifts` en el Primer Diccionario\n",
    "\n",
    "Calculamos la columna `lifts` que representa el incremento porcentual en ventas generado por las campañas de marketing comparado con el promedio por región.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "# El lift se interpreta como: el % de incremento de ventas generado por haber efectuado alguna de estas campañas de marketing en comparación con un escenario donde no se hubiera efectuado ninguna.\n",
    "for key, df in dataframes_target.items():\n",
    "    df['lifts'] = df['proporcion'] - df['promedio_proporcion_region']\n",
    "```\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "- **Cálculo del Lift**: La columna `lifts` se calcula como la diferencia entre `proporcion` y `promedio_proporcion_region`.\n",
    "- **Interpretación del Lift**: El lift se interpreta como el porcentaje de incremento en ventas generado por las campañas de marketing en comparación con un escenario donde no se hubiera efectuado ninguna campaña.\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "Este código calcula los promedios de `proporcion` por región para cada DataFrame en el segundo diccionario y añade estos promedios como una nueva columna en los DataFrames del primer diccionario. Luego, se calcula y añade la columna `lifts`, que mide el incremento porcentual en ventas debido a las campañas de marketing. Este proceso es crucial para analizar el impacto de las campañas de marketing de manera detallada y segmentada.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c608b92f-b148-486a-9108-854ae2daf8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtrar items cuyo primer elemento de la tupla es 'AUTOSERVICIOS'\n",
    "filtered_by_first = {k: v for k, v in dataframes_target.items() if k[0] == 'AUTOSERVICIOS' and k[1]=='andes_origen'}\n",
    "\n",
    "#filtered_by_first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b78a787d-adc6-41dd-bea2-59b27f891df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def wilcoxon_test(df, column_name):\n",
    "    \"\"\"\n",
    "    Realiza el test de Wilcoxon para una columna específica de un DataFrame.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame de pandas que contiene los datos.\n",
    "    - column_name: Nombre de la columna sobre la cual se realizará el test.\n",
    "\n",
    "    Retorna:\n",
    "    - 1 si se rechaza la hipótesis nula (la media es mayor que cero).\n",
    "    - 0 si no se puede rechazar la hipótesis nula.\n",
    "    \"\"\"\n",
    "    # Obtener los datos de la columna\n",
    "    data = df[column_name].values\n",
    "    \n",
    "    # Realizar el test de Wilcoxon unilateral para muestras independientes\n",
    "    stat, p_value = wilcoxon(data, alternative='greater')\n",
    "    \n",
    "    # Interpretar el resultado\n",
    "    alpha = 0.05  # Nivel de significancia\n",
    "    if p_value < alpha:\n",
    "        return 1  # Se rechaza la hipótesis nula\n",
    "    else:\n",
    "        return 0  # No se rechaza la hipótesis nula\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1aada7-324f-4c58-b434-c425223f0488",
   "metadata": {},
   "source": [
    "Este código implementa una función llamada `wilcoxon_test` que realiza el test de Wilcoxon para una columna específica de un DataFrame de pandas. \n",
    "\n",
    "1. **Importación de la función `wilcoxon` desde `scipy.stats`**:\n",
    "   ```python\n",
    "   from scipy.stats import wilcoxon\n",
    "   ```\n",
    "   Esto importa la función `wilcoxon` del módulo `scipy.stats`, que se utiliza para realizar el test de Wilcoxon.\n",
    "\n",
    "2. **Definición de la función `wilcoxon_test`**:\n",
    "   ```python\n",
    "   def wilcoxon_test(df, column_name):\n",
    "       \"\"\"\n",
    "       Realiza el test de Wilcoxon para una columna específica de un DataFrame.\n",
    "\n",
    "       Parámetros:\n",
    "       - df: DataFrame de pandas que contiene los datos.\n",
    "       - column_name: Nombre de la columna sobre la cual se realizará el test.\n",
    "\n",
    "       Retorna:\n",
    "       - 1 si se rechaza la hipótesis nula (la media es mayor que cero).\n",
    "       - 0 si no se puede rechazar la hipótesis nula.\n",
    "       \"\"\"\n",
    "   ```\n",
    "   - **Descripción y parámetros**: La función está documentada usando un docstring que explica su propósito, los parámetros que toma y lo que retorna. Toma como entrada un DataFrame `df` que contiene los datos y el nombre de la columna `column_name` sobre la cual se realizará el test.\n",
    "\n",
    "3. **Obtención de los datos de la columna**:\n",
    "   ```python\n",
    "       # Obtener los datos de la columna\n",
    "       data = df[column_name].values\n",
    "   ```\n",
    "   Aquí se extraen los valores de la columna especificada (`column_name`) del DataFrame `df` y se almacenan en la variable `data`. Estos datos se usarán como entrada para el test de Wilcoxon.\n",
    "\n",
    "4. **Ejecución del test de Wilcoxon**:\n",
    "   ```python\n",
    "       # Realizar el test de Wilcoxon unilateral para muestras independientes\n",
    "       stat, p_value = wilcoxon(data, alternative='greater')\n",
    "   ```\n",
    "   - **`wilcoxon(data, alternative='greater')`**: Esta línea ejecuta el test de Wilcoxon sobre los datos `data`. El parámetro `alternative='greater'` especifica que se está probando la hipótesis alternativa de que la media de la población subyacente es mayor que cero. El resultado del test (`stat`) y el valor p (`p_value`) se asignan a las variables correspondientes.\n",
    "\n",
    "5. **Interpretación del resultado**:\n",
    "   ```python\n",
    "       # Interpretar el resultado\n",
    "       alpha = 0.05  # Nivel de significancia\n",
    "       if p_value < alpha:\n",
    "           return 1  # Se rechaza la hipótesis nula\n",
    "       else:\n",
    "           return 0  # No se rechaza la hipótesis nula\n",
    "   ```\n",
    "   - Se define `alpha` como el nivel de significancia, comúnmente establecido en 0.05.\n",
    "   - Se compara el valor p (`p_value`) obtenido del test con `alpha`.\n",
    "   - Si `p_value` es menor que `alpha`, se rechaza la hipótesis nula (que en este caso sería que la media de la columna es mayor que cero) y la función retorna `1`.\n",
    "   - Si `p_value` es mayor o igual que `alpha`, no se puede rechazar la hipótesis nula y la función retorna `0`.\n",
    "\n",
    "En resumen, esta función `wilcoxon_test` utiliza el test de Wilcoxon para evaluar si la media de una columna específica de un DataFrame es mayor que cero. Retorna `1` si se rechaza la hipótesis nula (media mayor que cero), o `0` si no se puede rechazar la hipótesis nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e55f9ac0-dd79-48fc-8ea3-4e856e7b0299",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ejemplo de la función wilcoxon_test\n",
    "dft=dataframes_target[('AUTOSERVICIOS', 'andes_origen', '01')]\n",
    "wilcoxon_test(dft,'lifts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "966c6109-38cf-4f7a-a13d-f1e3e5137870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wilcoxon_test_lifts={}\n",
    "\n",
    "for key, df in dataframes_target.items():\n",
    "    wilcoxon_test_lifts[key]=wilcoxon_test(df,'lifts')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4007ec1b-96d2-4d1d-a59c-047d74adfbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rubro</th>\n",
       "      <th>brand</th>\n",
       "      <th>mes</th>\n",
       "      <th>campaña_exitosa</th>\n",
       "      <th>lifts_promedio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOSERVICIOS</td>\n",
       "      <td>andes_origen</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.420419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUTOSERVICIOS</td>\n",
       "      <td>andes_origen</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.673224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUTOSERVICIOS</td>\n",
       "      <td>andes_origen</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUTOSERVICIOS</td>\n",
       "      <td>andes_origen</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUTOSERVICIOS</td>\n",
       "      <td>andes_origen</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>TRADICIONAL</td>\n",
       "      <td>stella_artois</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>TRADICIONAL</td>\n",
       "      <td>stella_artois</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>TRADICIONAL</td>\n",
       "      <td>stella_artois</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>TRADICIONAL</td>\n",
       "      <td>stella_artois</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>TRADICIONAL</td>\n",
       "      <td>stella_artois</td>\n",
       "      <td>06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.083002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rubro          brand mes  campaña_exitosa  lifts_promedio\n",
       "0    AUTOSERVICIOS   andes_origen  01                1        0.420419\n",
       "1    AUTOSERVICIOS   andes_origen  02                1        0.673224\n",
       "2    AUTOSERVICIOS   andes_origen  03                1        0.590717\n",
       "3    AUTOSERVICIOS   andes_origen  04                1        0.558816\n",
       "4    AUTOSERVICIOS   andes_origen  05                1        0.398376\n",
       "..             ...            ...  ..              ...             ...\n",
       "123    TRADICIONAL  stella_artois  02                1        0.638055\n",
       "124    TRADICIONAL  stella_artois  03                1        0.915053\n",
       "125    TRADICIONAL  stella_artois  04                1        0.870266\n",
       "126    TRADICIONAL  stella_artois  05                0        0.052732\n",
       "127    TRADICIONAL  stella_artois  06                1        1.083002\n",
       "\n",
       "[128 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista para almacenar los datos\n",
    "data = []\n",
    "\n",
    "# Recorrer el diccionario y crear las tuplas para cada fila\n",
    "for key, value in wilcoxon_test_lifts.items():\n",
    "    rubro, brand, mes = key\n",
    "    l=dataframes_target[key]['lifts'].mean()\n",
    "    data.append((rubro, brand, mes, value,l))\n",
    "\n",
    "# Crear el DataFrame\n",
    "df = pd.DataFrame(data, columns=['rubro', 'brand', 'mes', 'campaña_exitosa','lifts_promedio'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d5beb64-dcc4-4b4e-bd59-18df77a779e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    66\n",
       "0    62\n",
       "Name: campaña_exitosa, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.campaña_exitosa.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7cc91-b05f-401f-a8f3-e4c2ab174603",
   "metadata": {},
   "source": [
    "Este código realiza lo siguiente:\n",
    "\n",
    "1. **Realización del test de Wilcoxon para cada grupo en `dataframes_target`**:\n",
    "   ```python\n",
    "   wilcoxon_test_lifts = {}\n",
    "\n",
    "   for key, df in dataframes_target.items():\n",
    "       wilcoxon_test_lifts[key] = wilcoxon_test(df, 'lifts')\n",
    "   ```\n",
    "   - Itera sobre cada elemento (`key, df`) en el diccionario `dataframes_target`.\n",
    "   - Para cada `df` (que representa un DataFrame agrupado por una combinación de rubro, marca y mes), se aplica la función `wilcoxon_test` para la columna 'lifts' y se guarda el resultado en `wilcoxon_test_lifts` usando `key` como clave.\n",
    "\n",
    "2. **Construcción de una lista de tuplas para crear el DataFrame**:\n",
    "   ```python\n",
    "   # Lista para almacenar los datos\n",
    "   data = []\n",
    "\n",
    "   # Recorrer el diccionario y crear las tuplas para cada fila\n",
    "   for key, value in wilcoxon_test_lifts.items():\n",
    "       rubro, brand, mes = key\n",
    "       data.append((rubro, brand, mes, value))\n",
    "   ```\n",
    "   - Se inicializa una lista vacía `data` para almacenar los datos del DataFrame final.\n",
    "   - Itera sobre `wilcoxon_test_lifts` y desempaqueta `key` en `rubro, brand, mes`.\n",
    "   - Para cada entrada en `wilcoxon_test_lifts`, se agrega una tupla `(rubro, brand, mes, value)` a la lista `data`, donde `value` es el resultado del test de Wilcoxon (1 si se rechaza la hipótesis nula, 0 si no).\n",
    "\n",
    "3. **Creación del DataFrame final**:\n",
    "   ```python\n",
    "   # Crear el DataFrame\n",
    "   df = pd.DataFrame(data, columns=['rubro', 'brand', 'mes', 'campaña_exitosa'])\n",
    "   ```\n",
    "   - Se crea un DataFrame `df` utilizando la lista `data`.\n",
    "   - Las columnas del DataFrame se especifican como `['rubro', 'brand', 'mes', 'campaña_exitosa']`.\n",
    "\n",
    "4. **Conteo de valores en la columna `campaña_exitosa`**:\n",
    "   ```python\n",
    "   df.campaña_exitosa.value_counts()\n",
    "   ```\n",
    "   - Utiliza el método `value_counts()` en la columna `campaña_exitosa` del DataFrame `df`.\n",
    "   - Esto cuenta cuántas veces aparece cada valor en la columna `campaña_exitosa` (en este caso, 0 y 1).\n",
    "\n",
    "El código genera un DataFrame (`df`) que resume los resultados del test de Wilcoxon para cada combinación de rubro, marca y mes en `dataframes_target`, indicando si la campaña fue exitosa (1) o no (0) según el resultado del test. Finalmente, muestra el conteo de los valores en la columna `campaña_exitosa` para evaluar la distribución de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eee6ef4b-35a1-403d-bf67-c443d101cb2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Guardamos la tabla con los lifts en un archivo csv\n",
    "#df.to_csv('lifts_tabla.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce569a06-5d0e-4a0d-aa7a-d3bd30afd66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048118237f434fc48caba266e088ef6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Marca:', options=('andes_origen', 'brahma', 'budweiser', 'corona', 'otras…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Función para actualizar el gráfico según la marca y rubro \n",
    "def update_graph(marca,rubro):\n",
    "    plt.clf()  # Limpiar el gráfico anterior\n",
    "    \n",
    "    # Filtrar los datos para la marca y rubro \n",
    "    data_filtered = df[(df['brand'] == marca) & (df['rubro'] == rubro)]\n",
    "    \n",
    "    # Configurar el estilo\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    barplot = sns.barplot(x='mes', y='lifts_promedio', data=data_filtered, palette='viridis', alpha=0.7)\n",
    "\n",
    "    # Añadir etiquetas y título\n",
    "    plt.title(f'Lifts promedio - {marca} - {rubro}', fontsize=13)\n",
    "    plt.xlabel('Periodo', fontsize=11)\n",
    "    plt.ylabel('Lifts', fontsize=11)\n",
    "\n",
    "    # Girar las etiquetas del eje x\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=7)\n",
    "    plt.yticks(fontsize=9)\n",
    "\n",
    "    # Añadir etiquetas de datos en las barras\n",
    "    for p in barplot.patches:\n",
    "        barplot.annotate(format(p.get_height(), '.1f'), \n",
    "                         (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                         ha='center', va='center', \n",
    "                         xytext=(0, 7),  # Distancia del texto a la barra\n",
    "                         textcoords='offset points',\n",
    "                         fontsize=7)  # Tamaño de la fuente más pequeño\n",
    "\n",
    "    # Mejorar el diseño del gráfico\n",
    "    sns.despine(left=True, bottom=True)\n",
    "\n",
    "    # Mostrar el gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Obtener la lista única de marcas\n",
    "marcas = df['brand'].unique()\n",
    "\n",
    "# Crear el widget de selección de marca\n",
    "marca_widget = widgets.Dropdown(\n",
    "    options=marcas,\n",
    "    value=marcas[0],  # Valor por defecto\n",
    "    description='Marca:'\n",
    ")\n",
    "\n",
    "# Obtener la lista única de rubros\n",
    "rubros = df['rubro'].unique()\n",
    "\n",
    "# Crear el widget de selección de rubros\n",
    "rubro_widget = widgets.Dropdown(\n",
    "    options=rubros,\n",
    "    value=rubros[0],  # Valor por defecto\n",
    "    description='Rubro:'\n",
    ")\n",
    "\n",
    "# Asociar la función de actualización al cambio en el widget\n",
    "output = widgets.interactive_output(update_graph, {'marca': marca_widget,'rubro': rubro_widget})\n",
    "\n",
    "# Mostrar el widget y la salida del gráfico\n",
    "display(widgets.HBox([marca_widget,rubro_widget, output]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8266bff9-6067-4c43-8136-32db76b7f3a1",
   "metadata": {},
   "source": [
    "### Descripción del Código\n",
    "\n",
    "#### 1. Función `update_graph`\n",
    "\n",
    "```python\n",
    "# Función para actualizar el gráfico según la marca y rubro \n",
    "def update_graph(marca, rubro):\n",
    "    plt.clf()  # Limpiar el gráfico anterior\n",
    "    \n",
    "    # Filtrar los datos para la marca y rubro \n",
    "    data_filtered = df[(df['brand'] == marca) & (df['rubro'] == rubro)]\n",
    "    \n",
    "    # Configurar el estilo\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    barplot = sns.barplot(x='mes', y='lifts_promedio', data=data_filtered, palette='viridis', alpha=0.7)\n",
    "\n",
    "    # Añadir etiquetas y título\n",
    "    plt.title(f'Lifts promedio - {marca} - {rubro}', fontsize=13)\n",
    "    plt.xlabel('Periodo', fontsize=11)\n",
    "    plt.ylabel('Lifts', fontsize=11)\n",
    "\n",
    "    # Girar las etiquetas del eje x\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=7)\n",
    "    plt.yticks(fontsize=9)\n",
    "\n",
    "    # Añadir etiquetas de datos en las barras\n",
    "    for p in barplot.patches:\n",
    "        barplot.annotate(format(p.get_height(), '.1f'), \n",
    "                         (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                         ha='center', va='center', \n",
    "                         xytext=(0, 7),  # Distancia del texto a la barra\n",
    "                         textcoords='offset points',\n",
    "                         fontsize=7)  # Tamaño de la fuente más pequeño\n",
    "\n",
    "    # Mejorar el diseño del gráfico\n",
    "    sns.despine(left=True, bottom=True)\n",
    "\n",
    "    # Mostrar el gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "- **Función `update_graph`**: Esta función toma dos argumentos, `marca` y `rubro`, que representan la marca y el rubro seleccionados por el usuario respectivamente.\n",
    "\n",
    "- **Filtrado de Datos**: Utiliza `df[(df['brand'] == marca) & (df['rubro'] == rubro)]` para filtrar el DataFrame `df` y obtener solo las filas donde la columna `brand` coincide con `marca` y la columna `rubro` coincide con `rubro`.\n",
    "\n",
    "- **Configuración del Gráfico**: \n",
    "  - `sns.set(style=\"whitegrid\")`: Configura el estilo de Seaborn para el gráfico.\n",
    "  - `plt.figure(figsize=(9, 6))`: Define el tamaño del gráfico.\n",
    "  - `sns.barplot(...)`: Crea un gráfico de barras utilizando Seaborn, donde `mes` se representa en el eje x, `lifts_promedio` en el eje y, y `data_filtered` contiene los datos filtrados para la marca y rubro seleccionados.\n",
    "\n",
    "- **Añadir Etiquetas y Título**: Configura el título del gráfico y etiquetas para los ejes x e y.\n",
    "\n",
    "- **Etiquetas de Datos**: Utiliza `annotate` para agregar etiquetas de datos en las barras del gráfico.\n",
    "\n",
    "- **Mejoras Estéticas**: `sns.despine()` elimina los bordes izquierdo y inferior del gráfico para mejorar la estética.\n",
    "\n",
    "- **Mostrar el Gráfico**: `plt.tight_layout()` asegura que todos los elementos del gráfico sean visibles correctamente, y `plt.show()` muestra el gráfico en el notebook.\n",
    "\n",
    "#### 2. Widgets Interactivos y Visualización\n",
    "\n",
    "```python\n",
    "# Obtener la lista única de marcas\n",
    "marcas = df['brand'].unique()\n",
    "\n",
    "# Crear el widget de selección de marca\n",
    "marca_widget = widgets.Dropdown(\n",
    "    options=marcas,\n",
    "    value=marcas[0],  # Valor por defecto\n",
    "    description='Marca:'\n",
    ")\n",
    "\n",
    "# Obtener la lista única de rubros\n",
    "rubros = df['rubro'].unique()\n",
    "\n",
    "# Crear el widget de selección de rubros\n",
    "rubro_widget = widgets.Dropdown(\n",
    "    options=rubros,\n",
    "    value=rubros[0],  # Valor por defecto\n",
    "    description='Rubro:'\n",
    ")\n",
    "\n",
    "# Asociar la función de actualización al cambio en el widget\n",
    "output = widgets.interactive_output(update_graph, {'marca': marca_widget, 'rubro': rubro_widget})\n",
    "\n",
    "# Mostrar el widget y la salida del gráfico\n",
    "display(widgets.HBox([marca_widget, rubro_widget, output]))\n",
    "```\n",
    "\n",
    "- **Widgets de Selección**: \n",
    "  - `marca_widget`: Es un widget `Dropdown` que permite al usuario seleccionar una marca de cerveza de la lista de marcas únicas obtenidas de la columna `brand` en el DataFrame `df`.\n",
    "  - `rubro_widget`: Es otro widget `Dropdown` que permite al usuario seleccionar un rubro de la lista de rubros únicos obtenidos de la columna `rubro` en el DataFrame `df`.\n",
    "\n",
    "- **Asociación con la Función `update_graph`**: `widgets.interactive_output` conecta dinámicamente los widgets `marca_widget` y `rubro_widget` con la función `update_graph`, de modo que cada vez que se selecciona una marca o rubro, se llama automáticamente a `update_graph` con los valores seleccionados como argumentos.\n",
    "\n",
    "- **Mostrar el Widget y la Salida**: `display(widgets.HBox([...]))` muestra los widgets de selección de marca y rubro, así como la salida interactiva del gráfico, colocándolos en una misma fila (`HBox`), lo cual facilita la interacción y visualización en el notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb9dab-c4aa-4eb5-b67e-da51b3883ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
